{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting clicks on log streams using Elastic MapReduce (EMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is a sample of Adform's ad traffic.\n",
    "\n",
    "Each record corresponds to an ad impression served by Adform, and consists of a single binary label (clicked/not-clicked) and a selected subset of features (c0-c9). The positives and negatives are downsampled at different rates. The data is chronologically ordered.\n",
    "\n",
    "The file is gzipped and each line corresponds to a single record, serialized as JSON. The JSON has the following fields:\n",
    "\n",
    "\"l\": The binary label indicating whether the ad was clicked (1) or not (0).\n",
    "\"c0\" - \"c9\": Categorical features which were hashed into a 32-bit integer.\n",
    "The semantics of the features are not disclosed. The values are stored in an array, because some of the features have multiple values per record. When a key is missing, the field is empty.\n",
    "\n",
    "    The dataset is large enough (5GB). We need multiple machines to performing the train. Therefore, will use \n",
    "    AWS EMR (Elastic MapReduce) in the train of a classifier capable of predicting whether a user will click on an advertisement given certain conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting Spark application and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run in aws-emr\n",
    "#s3_train_path = 's3://mastering-ml-aws/chapter4'\n",
    "\n",
    "#run local\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext('local', 'Pred_clicks')\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-------------+-------------+------------+-------------+--------------------+-------------+------------+--------------------+---+\n",
      "|           c0|          c1|           c2|           c3|          c4|           c5|                  c6|           c7|          c8|                  c9|  l|\n",
      "+-------------+------------+-------------+-------------+------------+-------------+--------------------+-------------+------------+--------------------+---+\n",
      "|[-1664374510]|[1292560685]| [1963151207]| [-113426919]|[1024827180]|         null|[-1841755489, -20...|  [781804810]| [677061876]|[-2054476127, 128...|  0|\n",
      "| [1566608579]|[-248982458]|  [336746857]|[-1629610286]| [244157766]|         null|[-574085389, 1869...| [1065163157]| [332083152]|        [-614983515]|  0|\n",
      "| [1935105702]|[1292560685]|[-1389162932]| [-113426919]|  [-8361123]|  [839761088]|                null|[-1708330775]|[1856995055]|[-1954958362, 157...|  0|\n",
      "| [1718276659]| [630920017]| [1171414431]| [-113426919]| [640993460]|[-1183679474]|[-833071846, 1997...|  [680566046]|[-681791195]|[-813776566, 1925...|  1|\n",
      "| [1562430026]| [630920017]| [1639152385]| [1781226914]|[1493440023]|         null|[-2043098156, -95...|  [324520841]| [873551722]|         [980231370]|  0|\n",
      "+-------------+------------+-------------+-------------+------------+-------------+--------------------+-------------+------------+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run in aws-emr\n",
    "#ctr_df = spark.read.json('adform.click.2017.01.json')\n",
    "\n",
    "#run local\n",
    "ctr_df = sql.read.json('adform.click.2017.01.json')\n",
    "ctr_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our dataset has 10 features and 1 column indicating the label that we're trying to predict if the user: \n",
    "           \n",
    "           clicked (1) or didin't clicked (0) on the advertisement.\n",
    "           \n",
    "           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the code, we will pick the first five features by constructing  a dataset and rename these features as f0, f1,f2 and f3. we will also replace null features with the value 0 and only take the first value in the case of multivalued features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+-----------+-----------+-----+\n",
      "|         f0|         f1|         f2|         f3|         f4|click|\n",
      "+-----------+-----------+-----------+-----------+-----------+-----+\n",
      "|-1664374510| 1292560685| 1963151207| -113426919| 1024827180|    0|\n",
      "| 1566608579| -248982458|  336746857|-1629610286|  244157766|    0|\n",
      "| 1935105702| 1292560685|-1389162932| -113426919|   -8361123|    0|\n",
      "| 1718276659|  630920017| 1171414431| -113426919|  640993460|    1|\n",
      "| 1562430026|  630920017| 1639152385| 1781226914| 1493440023|    0|\n",
      "|-1322326169| 1338259132|-1389162932|          0|-1658448827|    0|\n",
      "| 1059882129| 2000378252|-1389162932|          0|-1530435578|    0|\n",
      "|-1322326169| -642801039|-1389162932|          0| -457281581|    0|\n",
      "|-1410788805| -409082697|-1389162932|          0| 2002120008|    0|\n",
      "|  539933552|  630920017|-1389162932| -113426919|  326407952|    0|\n",
      "|  539933552|  630920017|-1389162932| -113426919|  326407952|    0|\n",
      "|-1296787258| 2060859103|-2081862133| -113426919| 1699915016|    1|\n",
      "| 1580809047|  856005849| -519038014| 1781226914| 1579313884|    0|\n",
      "|-2047712504|  630920017|-1720999986| 1781226914| 1858142835|    0|\n",
      "|-1449821180| 1005318208|   43087058|          0|  -70952381|    0|\n",
      "| 1156777826|-2015239481|-1389162932| -500159989| 1329136269|    0|\n",
      "| 1095250594|  630920017|-1389162932|          0|  798952030|    0|\n",
      "|-1326579112|-1152260779|-1389162932|          0| 1787048753|    0|\n",
      "|-1883822262|-2015239481|  -25698638|          0| -849192713|    0|\n",
      "| -819024248|-1102198532|-1389162932|          0|  713018946|    1|\n",
      "+-----------+-----------+-----------+-----------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = ctr_df.selectExpr(\"coalesce(c0[0],0) as f0\",\n",
    "                       \"coalesce(c1[0],0) as f1\",\n",
    "                       \"coalesce(c2[0],0) as f2\",\n",
    "                       \"coalesce(c3[0],0) as f3\",\n",
    "                       \"coalesce(c4[0],0) as f4\",\n",
    "                       \"l as click\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshuffle the different portions of the csv into different machines and cache them in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run in aws-arm\n",
    "#df = df.repartition(100).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+-------------------+--------------------+------------------+\n",
      "|summary|                  f0|                  f1|                  f2|                 f3|                  f4|             click|\n",
      "+-------+--------------------+--------------------+--------------------+-------------------+--------------------+------------------+\n",
      "|  count|            12000000|            12000000|            12000000|           12000000|            12000000|          12000000|\n",
      "|   mean|-6.610412663970825E7|2.5049429668800482E8|-2.915904354482062E8|5.459869260236725E7|-6.716129061083934E7|        0.18310175|\n",
      "| stddev|1.2294656059145827E9| 1.287445524252861E9|1.2580392622053537E9|8.234483651283174E8| 1.242913446913509E9|0.3867499342101615|\n",
      "|    min|         -2145952914|         -2125813709|         -2145112401|        -2134594413|         -2147400218|                 0|\n",
      "|    max|          2146734164|          2136145316|          2145529900|         2102865870|          2147086554|                 1|\n",
      "+-------+--------------------+--------------------+--------------------+-------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       The mean value for the Click column informs us that there is certain degree of label imbalance(as about 18% of the instances are Clicks). Additionally, the count row tell us that there is a total of 12,000,000 rows in our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique values for each features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2497"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('f0').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('f1').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('f2').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('f3').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17572"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('f4').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|         f0|f0_index|\n",
      "+-----------+--------+\n",
      "|-1664374510|   140.0|\n",
      "| 1566608579|   455.0|\n",
      "| 1935105702|    44.0|\n",
      "| 1718276659|  1540.0|\n",
      "+-----------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "indexer = StringIndexer(inputCol = 'f0', outputCol = 'f0_index')\n",
    "ctr_df_indexed = indexer.fit(df)\n",
    "df_indexed = ctr_df_indexed.transform(df).select('f0','f0_index')\n",
    "df_indexed.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------------------+\n",
      "|         f0|f0_index|        f0_encoded|\n",
      "+-----------+--------+------------------+\n",
      "|-1156005499|   337.0|(2496,[337],[1.0])|\n",
      "|-1713169383|   242.0|(2496,[242],[1.0])|\n",
      "|-1577432220|   408.0|(2496,[408],[1.0])|\n",
      "| -293118980|   401.0|(2496,[401],[1.0])|\n",
      "+-----------+--------+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"f0_index\", outputCol=\"f0_encoded\")\n",
    "encoder.transform(df_indexed).distinct().show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and Training a Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_one_hot_encoding(columns):\n",
    "    indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\", handleInvalid='keep') for column in columns]\n",
    "    encoders = [OneHotEncoder(inputCol=column + \"_index\", outputCol=column + \"_encoded\") for column in columns]\n",
    "\n",
    "    return indexers + encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['f0','f1','f2','f3','f4']\n",
    "encoded_columns = [column + '_encoded' for column in categorical_columns] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the high number of features due the One-Hot encoder, the feature vector can be huge and make the trainer very slow or require massive amounts of memory. One way to mitigate that is to use a **Chi-squared** feature selector. We will select the best 100 features\n",
    "\n",
    "[Chi-Squared Test for Feature Selection with implementation in Python](https://towardsdatascience.com/chi-squared-test-for-feature-selection-with-implementation-in-python-65b4ae7696db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "\n",
    "\n",
    "\n",
    "categorical_stages = categorical_one_hot_encoding(categorical_columns)\n",
    "vector_assembler = VectorAssembler(inputCols=encoded_columns, outputCol=\"features\")\n",
    "\n",
    "selector = ChiSqSelector(numTopFeatures=100, featuresCol=\"features\",\n",
    "                         outputCol=\"selected_features\", labelCol=\"click\")\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(labelCol=\"click\", featuresCol=\"selected_features\")\n",
    "\n",
    "encoding_pipeline = Pipeline(stages=categorical_stages + [vector_assembler, selector, decision_tree])\n",
    "\n",
    "#\n",
    "#encoding_pipeline = Pipeline(stages=categorical_stages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = encoding_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.transform(train_df).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC - area under the ROC curve\n",
    "\n",
    "\n",
    "[The 5 Classification Evaluation metrics every Data Scientist must know](https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"click\")\n",
    "evaluator.evaluate(pipeline_model.transform(test_df), {evaluator.metricName: \"areaUnderROC\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Tree Ensembles on EMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(labelCol=\"click\", featuresCol=\"features\")\n",
    "pipeline_rf = Pipeline(stages=categorical_stages + [vector_assembler, random_forest])\n",
    "\n",
    "\n",
    "rf_pipeline_model = pipeline_rf.fit(train_df)\n",
    "evaluator.evaluate(rf_pipeline_model.transform(test_df), {evaluator.metricName: \"areaUnderROC\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
